<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pyIFD.NOI5 API documentation</title>
<meta name="description" content="This module provides the NOI5 algorithm" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyIFD.NOI5</code></h1>
</header>
<section id="section-intro">
<p>This module provides the NOI5 algorithm</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module provides the NOI5 algorithm
&#34;&#34;&#34;

import numpy as np
from numpy.linalg import eigh
import cv2
from scipy.ndimage import median_filter as medfilt

def KMeans(data,N):
    &#34;&#34;&#34;
    Sorts data into N bins.
    
    Args:
        data: data to be sorted 
        N: number of bins to be sorted into 
    
    Returns:
        u: means of the bins
        re: If data is a nx1 vector, this will be a nx2 output. The first column will be the point, and the second will be its bin assignment
    &#34;&#34;&#34;
    m = data.size
    u=np.zeros((N,1));
    Sdata = np.sort(data);
    u[0] = np.mean(Sdata[-round(m/4)-1:])
    u[1] = np.mean(Sdata[:round(m/4)])
    umax = np.median(Sdata[-round(m/10)-1:])
    data[data&gt;umax]= umax
    for iter in range(200):
        pre_u=u.copy()     #center of the last iter
        tmp=np.zeros((N,m))
        for i in range(N):
            tmp[i,:]=data-u[i]
        tmp = np.abs(tmp)
        junk=np.min(tmp,axis=0)
        index=np.argmin(tmp,axis=0)
        quan=np.zeros((m,N))
        for i in range(m):          
            quan[i,index[i]]=junk[i]
        for i in range(N): 
            if (np.sum(quan[:,i])&gt;0.01):
                u[i]= np.sum(quan[:,i]*data)/np.sum(quan[:,i]);
        
        if (np.linalg.norm(pre_u-u)&lt;0.02): 
            break;
    
    re=np.zeros((m,2))
    for i in range(m):
        tmp=np.zeros((N,1))
        for j in range(N):
            tmp[j]=np.linalg.norm(data[i]-u[j])
        
        junk=np.min(tmp,axis=0)
        index=np.argmin(tmp,axis=0)
        re[i,0]=data[i]
        re[i,1]=index+1
    # the tampered area is less than half of the whole image
    label = re[:,1]
    if list(label).count(1)&lt;int(m/2):
        re[:,1]=3-label
    
    return [u,re]

def PCANoiseLevelEstimator( image, Bsize ):
    &#34;&#34;&#34;
    Summary please.

    Args:
        image: Image to process
        Bsize:

    Returns:
        label:
        variance: 
    &#34;&#34;&#34;
    UpperBoundLevel             = 0.0005
    UpperBoundFactor            = 3.1
    M1                          = Bsize
    M2                          = Bsize
    M                           = M1 * M2
    EigenValueCount             = 7
    EigenValueDiffThreshold     = 49.0
    LevelStep                   = 0.05
    MinLevel                    = 0.06
    MaxClippedPixelCount        = round(np.nextafter(0.1*M,0.1*M+1))
    
    #==========================================================================
    def Clamp(x, a, b):
        &#34;&#34;&#34;
        Limit input value to a range.

        Args:
            x: value to clamp
            a: minimum value
            b: maximum value

        Returns:
            y: clamped value
        &#34;&#34;&#34;        
        y=x
        if x &lt; a:
            y = a
        if x &gt; b:
            y = b
        return y

    #==========================================================================
    def ComputeBlockInfo(image):
        &#34;&#34;&#34;
        Summary please.

        Args:
            image:

        Returns:
            block_info: 
        &#34;&#34;&#34;        
        block_info = np.zeros((np.shape(image)[0]*np.shape(image)[1],3))
        block_count = 0

        for y in range(1,np.shape(image)[0] - M2+1):
            for x in range(1,np.shape(image)[1] - M1+1):  
                sum1 = 0.0
                sum2 = 0.0
                clipped_pixel_count = 0;

                for by in range(y-1,y + M2 - 1):
                    for bx in range(x-1,x + M1 - 1):                        
                        val = image[by,bx]
                        sum1 += val
                        sum2 += val**2

                        if val == 0 or val == 255:
                            clipped_pixel_count += 1
                if clipped_pixel_count &lt;= MaxClippedPixelCount:                   
                    block_info[block_count,0] = (sum2 - sum1*sum1/M) / M
                    block_info[block_count,1] = x
                    block_info[block_count,2] = y
                    block_count += 1 
        block_info=np.delete(block_info,slice(block_count,np.shape(image)[0]*np.shape(image)[1]),0)
        return block_info
    #==========================================================================
    def ComputeStatistics(image, block_info):
        &#34;&#34;&#34;
        Summary please.

        Args:
            image:
            block_info:

        Returns:
            sum1:
            sum2:
            subset_size:
        &#34;&#34;&#34;        
        loop_iters=len(np.arange(1,MinLevel,-0.05))
        sum1 = np.zeros((M,1,loop_iters))
        sum2 =  np.zeros((M,M,loop_iters))
        subset_size = np.zeros((loop_iters,1))
        subset_count = 0
        max_index=np.shape(block_info)[0]-1
        for p  in np.arange(1,MinLevel,-LevelStep):
            q = 0
            if p - LevelStep &gt; MinLevel:
                q = p - LevelStep

            beg_index = Clamp( round(q*max_index+LevelStep/2) + 1, 1, max_index+1 )
            end_index = Clamp( round(p*max_index+LevelStep/2) + 1, 1, max_index+1 )
            curr_sum1 = np.zeros((M, 1))
            curr_sum2 = np.zeros((M,M))
            for k in range (int(beg_index)-1,int(end_index)-1):
                curr_x = int(block_info[k,1])
                curr_y = int(block_info[k,2])
                block = np.reshape( image[curr_y-1 : curr_y+M2-1, curr_x-1 : curr_x+M1-1], (M, 1),order=&#39;F&#39; ).astype(&#34;double&#34;)
                curr_sum1 += block
                curr_sum2 +=  block * block.T
            subset_count += 1
            sum1[:,:,subset_count-1] = curr_sum1.copy()
            sum2[:,:,subset_count-1] = curr_sum2.copy()
            subset_size[subset_count-1] = end_index - beg_index
        for i in range(len(subset_size)-1,0,-1):
            sum1[:,:,i-1] += sum1[:,:,i]
            sum2[:,:,i-1] += sum2[:,:,i]
            subset_size[i-1] += subset_size[i]
        return [sum1,sum2,subset_size]
    #==========================================================================
    def ComputeUpperBound(block_info):
        &#34;&#34;&#34;
        Summary please.

        Args:
            block_info:

        Returns:
            upper_bound: 
        &#34;&#34;&#34;        
        max_index = np.shape(block_info)[0] - 1
        zero_idx=np.where(block_info[:,0]== 0)[0]
        if zero_idx.size==0:
            nozeroindex=round(UpperBoundLevel*max_index)
        else:
            nozeroindex = min(np.max(np.where(block_info[:,0]== 0)[0])+1,np.shape(block_info)[0]-1)
        index = Clamp(round(UpperBoundLevel*max_index) + 1, nozeroindex, np.shape(block_info)[0]-1)
        upper_bound = UpperBoundFactor * block_info[index,0]
        return upper_bound
    #==========================================================================
    def ApplyPCA( sum1, sum2, subset_size ):        
        &#34;&#34;&#34;
        Summary please.

        Args:
            sum1: Matrix one for PCA
            sum2: Matrix two for PCA
            subset_size: Vector for subset size

        Returns:
            eigh: Eigenvalues.
        &#34;&#34;&#34;                
        meanval = sum1 / subset_size
        cov_matrix = sum2 / subset_size - meanval * np.transpose(meanval)
        return eigh(cov_matrix)[0]
    #==========================================================================
    def GetNextEstimate( sum1, sum2, subset_size, prev_estimate, upper_bound ):
        &#34;&#34;&#34;
        Summary please.

        Args:
            sum1:
            sum2:
            subset_size:
            prev_estimate:
            upper_bound:

        Returns:
            variance: 
        &#34;&#34;&#34;                
        variance = 0;       
        for i in range(len(subset_size)):
            eigen_value = ApplyPCA( sum1[:,:,i], sum2[:,:,i], subset_size[i])
            variance=eigen_value[0]
            if variance &lt; 0.00001: #1e-5: 
                break;
            diff            = eigen_value[EigenValueCount-1] - eigen_value[0]
            diff_threshold  = EigenValueDiffThreshold * prev_estimate / subset_size[i]**0.5

            if( diff &lt; diff_threshold and variance &lt; upper_bound ):
                break;
        return variance

    #==========================================================================
   
    label = 0
    block_info = ComputeBlockInfo( image )
    if np.min(np.shape(block_info))==0:
        label = 1
        variance = np.var(image)
    else:
        idx=np.lexsort((block_info[:,2],block_info[:,0]))
        block_info = np.asarray([block_info[i,:] for i in idx])
        [sum1, sum2, subset_size] = ComputeStatistics( image, block_info )
        if subset_size[-1] == 0:
            label = 1
            variance = np.var(image)
        else:
            upper_bound = ComputeUpperBound( block_info )
            prev_variance = 0
            variance = upper_bound
            for iter in range(10):
                if( np.abs(prev_variance - variance) &lt; 0.00001): 
                    break
                prev_variance = variance
                variance = GetNextEstimate( sum1, sum2, subset_size, variance, upper_bound )
            if variance &lt; 0: 
                label = 1
                variance = np.var(image)
    variance = np.sqrt(variance)
    return [label, variance]

def PCANoise(impath):
    &#34;&#34;&#34;
    Main driver for NOI5 algorithm.
    
    Args:
        impath: input image path.
    
    Returns:
        Noise_mix2: OutputMap
        bwpp: OutputMap (Quantized)

    &#34;&#34;&#34;
    B = 64
    I = cv2.cvtColor(cv2.imread(impath), cv2.COLOR_BGR2GRAY).astype(&#34;double&#34;)
    [M,N] = np.shape(I)
    I = I[:int(np.floor(M/B)*B),:int(np.floor(N/B)*B)]
    [M, N] = np.shape(I)
    im = I.copy()
    irange = int(np.floor(M/B))
    jrange = int(np.floor(N/B))
    Ib=np.zeros((irange,jrange))
    label64=np.zeros((irange,jrange))
    Noise_64=np.zeros((irange,jrange))

    for i in range(irange):
        for j in range(jrange):
            Ib = I[i*B:(i+1)*B,j*B:(j+1)*B]
            Noise_64[i,j] =  PCANoiseLevelEstimator(Ib,5)[1]
    [u,re]  = KMeans(Noise_64.flatten(order=&#39;F&#39;),2)
    result4 = np.reshape(re[:,1],np.shape(Noise_64),order=&#39;F&#39;)

    
    B = 32
    irange = int(np.floor(M/B))
    jrange = int(np.floor(N/B))
    label32=np.zeros((irange,jrange))
    Noise_32=np.zeros((irange,jrange))
    for i  in range(irange):
        for j in range(jrange):
            Ib = I[i*B:(i+1)*B,j*B:(j+1)*B]
            [label32[i,j], Noise_32[i,j]] =  PCANoiseLevelEstimator(Ib,5)
    MEDNoise_32= medfilt(Noise_32,[5, 5])
    Noise_32[label32==1]= MEDNoise_32[label32==1]
    [u, re]=KMeans(Noise_32.flatten(order=&#39;F&#39;),2)
    result2=np.reshape(re[:,1],np.shape(Noise_32),order=&#39;F&#39;)
    irange = int(M/64)
    jrange = int(N/64)
    Noise_mix=np.zeros((irange*2,jrange*2))
    initialdetected=np.zeros((irange*2,jrange*2))
    for i in range(irange):
        for j in range(jrange):
            Noise_mix[2*i:2*(i+1),2*j:2*(j+1)] = Noise_64[i,j]
            initialdetected[2*i:2*(i+1),2*j:2*(j+1)] = result4[i,j]
    Noise_mix = 0.8*Noise_mix+0.2*Noise_32[:2*(i+1),:2*(j+1)]
    Noise_mix2 = Noise_mix.copy()
    DL = initialdetected[1:-1,:-2] - initialdetected[1:-1,1:-1]
    DR = initialdetected[1:-1,1:-1] - initialdetected[1:-1,2:]
    DU = initialdetected[:-2,1:-1] - initialdetected[1:-1,1:-1]
    DD = initialdetected[1:-1,1:-1] - initialdetected[2:,1:-1]
    Edge = np.zeros(np.shape(initialdetected))
    Edge[1:-1,1:-1]= np.abs(DL)+np.abs(DR)+np.abs(DU)+np.abs(DD)
    g = [Edge&gt;0]
    Noise_mix2[tuple(g)] = Noise_32[tuple(g)]
    [u,re]=KMeans(Noise_mix2.flatten(order=&#39;F&#39;),2)
    result4=np.reshape(re[:,1],np.shape(Noise_mix2),order=&#39;F&#39;)
    labels=cv2.connectedComponentsWithStats(np.uint8(result4-1))
    bwpp=labels[1]
    area = labels[2][:,4]
    for num in range(1,len(area)):
        if (area[num] &lt; 4):
            result4[bwpp==num]=1
    bwpp = cv2.connectedComponents(np.uint8(result4-1))[1]
    return [Noise_mix2,bwpp.astype(&#34;uint8&#34;)]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pyIFD.NOI5.KMeans"><code class="name flex">
<span>def <span class="ident">KMeans</span></span>(<span>data, N)</span>
</code></dt>
<dd>
<div class="desc"><p>Sorts data into N bins.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong></dt>
<dd>data to be sorted </dd>
<dt><strong><code>N</code></strong></dt>
<dd>number of bins to be sorted into </dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>u</code></dt>
<dd>means of the bins</dd>
<dt><code>re</code></dt>
<dd>If data is a nx1 vector, this will be a nx2 output. The first column will be the point, and the second will be its bin assignment</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def KMeans(data,N):
    &#34;&#34;&#34;
    Sorts data into N bins.
    
    Args:
        data: data to be sorted 
        N: number of bins to be sorted into 
    
    Returns:
        u: means of the bins
        re: If data is a nx1 vector, this will be a nx2 output. The first column will be the point, and the second will be its bin assignment
    &#34;&#34;&#34;
    m = data.size
    u=np.zeros((N,1));
    Sdata = np.sort(data);
    u[0] = np.mean(Sdata[-round(m/4)-1:])
    u[1] = np.mean(Sdata[:round(m/4)])
    umax = np.median(Sdata[-round(m/10)-1:])
    data[data&gt;umax]= umax
    for iter in range(200):
        pre_u=u.copy()     #center of the last iter
        tmp=np.zeros((N,m))
        for i in range(N):
            tmp[i,:]=data-u[i]
        tmp = np.abs(tmp)
        junk=np.min(tmp,axis=0)
        index=np.argmin(tmp,axis=0)
        quan=np.zeros((m,N))
        for i in range(m):          
            quan[i,index[i]]=junk[i]
        for i in range(N): 
            if (np.sum(quan[:,i])&gt;0.01):
                u[i]= np.sum(quan[:,i]*data)/np.sum(quan[:,i]);
        
        if (np.linalg.norm(pre_u-u)&lt;0.02): 
            break;
    
    re=np.zeros((m,2))
    for i in range(m):
        tmp=np.zeros((N,1))
        for j in range(N):
            tmp[j]=np.linalg.norm(data[i]-u[j])
        
        junk=np.min(tmp,axis=0)
        index=np.argmin(tmp,axis=0)
        re[i,0]=data[i]
        re[i,1]=index+1
    # the tampered area is less than half of the whole image
    label = re[:,1]
    if list(label).count(1)&lt;int(m/2):
        re[:,1]=3-label
    
    return [u,re]</code></pre>
</details>
</dd>
<dt id="pyIFD.NOI5.PCANoise"><code class="name flex">
<span>def <span class="ident">PCANoise</span></span>(<span>impath)</span>
</code></dt>
<dd>
<div class="desc"><p>Main driver for NOI5 algorithm.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>impath</code></strong></dt>
<dd>input image path.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Noise_mix2</code></dt>
<dd>OutputMap</dd>
<dt><code>bwpp</code></dt>
<dd>OutputMap (Quantized)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def PCANoise(impath):
    &#34;&#34;&#34;
    Main driver for NOI5 algorithm.
    
    Args:
        impath: input image path.
    
    Returns:
        Noise_mix2: OutputMap
        bwpp: OutputMap (Quantized)

    &#34;&#34;&#34;
    B = 64
    I = cv2.cvtColor(cv2.imread(impath), cv2.COLOR_BGR2GRAY).astype(&#34;double&#34;)
    [M,N] = np.shape(I)
    I = I[:int(np.floor(M/B)*B),:int(np.floor(N/B)*B)]
    [M, N] = np.shape(I)
    im = I.copy()
    irange = int(np.floor(M/B))
    jrange = int(np.floor(N/B))
    Ib=np.zeros((irange,jrange))
    label64=np.zeros((irange,jrange))
    Noise_64=np.zeros((irange,jrange))

    for i in range(irange):
        for j in range(jrange):
            Ib = I[i*B:(i+1)*B,j*B:(j+1)*B]
            Noise_64[i,j] =  PCANoiseLevelEstimator(Ib,5)[1]
    [u,re]  = KMeans(Noise_64.flatten(order=&#39;F&#39;),2)
    result4 = np.reshape(re[:,1],np.shape(Noise_64),order=&#39;F&#39;)

    
    B = 32
    irange = int(np.floor(M/B))
    jrange = int(np.floor(N/B))
    label32=np.zeros((irange,jrange))
    Noise_32=np.zeros((irange,jrange))
    for i  in range(irange):
        for j in range(jrange):
            Ib = I[i*B:(i+1)*B,j*B:(j+1)*B]
            [label32[i,j], Noise_32[i,j]] =  PCANoiseLevelEstimator(Ib,5)
    MEDNoise_32= medfilt(Noise_32,[5, 5])
    Noise_32[label32==1]= MEDNoise_32[label32==1]
    [u, re]=KMeans(Noise_32.flatten(order=&#39;F&#39;),2)
    result2=np.reshape(re[:,1],np.shape(Noise_32),order=&#39;F&#39;)
    irange = int(M/64)
    jrange = int(N/64)
    Noise_mix=np.zeros((irange*2,jrange*2))
    initialdetected=np.zeros((irange*2,jrange*2))
    for i in range(irange):
        for j in range(jrange):
            Noise_mix[2*i:2*(i+1),2*j:2*(j+1)] = Noise_64[i,j]
            initialdetected[2*i:2*(i+1),2*j:2*(j+1)] = result4[i,j]
    Noise_mix = 0.8*Noise_mix+0.2*Noise_32[:2*(i+1),:2*(j+1)]
    Noise_mix2 = Noise_mix.copy()
    DL = initialdetected[1:-1,:-2] - initialdetected[1:-1,1:-1]
    DR = initialdetected[1:-1,1:-1] - initialdetected[1:-1,2:]
    DU = initialdetected[:-2,1:-1] - initialdetected[1:-1,1:-1]
    DD = initialdetected[1:-1,1:-1] - initialdetected[2:,1:-1]
    Edge = np.zeros(np.shape(initialdetected))
    Edge[1:-1,1:-1]= np.abs(DL)+np.abs(DR)+np.abs(DU)+np.abs(DD)
    g = [Edge&gt;0]
    Noise_mix2[tuple(g)] = Noise_32[tuple(g)]
    [u,re]=KMeans(Noise_mix2.flatten(order=&#39;F&#39;),2)
    result4=np.reshape(re[:,1],np.shape(Noise_mix2),order=&#39;F&#39;)
    labels=cv2.connectedComponentsWithStats(np.uint8(result4-1))
    bwpp=labels[1]
    area = labels[2][:,4]
    for num in range(1,len(area)):
        if (area[num] &lt; 4):
            result4[bwpp==num]=1
    bwpp = cv2.connectedComponents(np.uint8(result4-1))[1]
    return [Noise_mix2,bwpp.astype(&#34;uint8&#34;)]</code></pre>
</details>
</dd>
<dt id="pyIFD.NOI5.PCANoiseLevelEstimator"><code class="name flex">
<span>def <span class="ident">PCANoiseLevelEstimator</span></span>(<span>image, Bsize)</span>
</code></dt>
<dd>
<div class="desc"><p>Summary please.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong></dt>
<dd>Image to process</dd>
</dl>
<p>Bsize:</p>
<h2 id="returns">Returns</h2>
<p>label:
variance:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def PCANoiseLevelEstimator( image, Bsize ):
    &#34;&#34;&#34;
    Summary please.

    Args:
        image: Image to process
        Bsize:

    Returns:
        label:
        variance: 
    &#34;&#34;&#34;
    UpperBoundLevel             = 0.0005
    UpperBoundFactor            = 3.1
    M1                          = Bsize
    M2                          = Bsize
    M                           = M1 * M2
    EigenValueCount             = 7
    EigenValueDiffThreshold     = 49.0
    LevelStep                   = 0.05
    MinLevel                    = 0.06
    MaxClippedPixelCount        = round(np.nextafter(0.1*M,0.1*M+1))
    
    #==========================================================================
    def Clamp(x, a, b):
        &#34;&#34;&#34;
        Limit input value to a range.

        Args:
            x: value to clamp
            a: minimum value
            b: maximum value

        Returns:
            y: clamped value
        &#34;&#34;&#34;        
        y=x
        if x &lt; a:
            y = a
        if x &gt; b:
            y = b
        return y

    #==========================================================================
    def ComputeBlockInfo(image):
        &#34;&#34;&#34;
        Summary please.

        Args:
            image:

        Returns:
            block_info: 
        &#34;&#34;&#34;        
        block_info = np.zeros((np.shape(image)[0]*np.shape(image)[1],3))
        block_count = 0

        for y in range(1,np.shape(image)[0] - M2+1):
            for x in range(1,np.shape(image)[1] - M1+1):  
                sum1 = 0.0
                sum2 = 0.0
                clipped_pixel_count = 0;

                for by in range(y-1,y + M2 - 1):
                    for bx in range(x-1,x + M1 - 1):                        
                        val = image[by,bx]
                        sum1 += val
                        sum2 += val**2

                        if val == 0 or val == 255:
                            clipped_pixel_count += 1
                if clipped_pixel_count &lt;= MaxClippedPixelCount:                   
                    block_info[block_count,0] = (sum2 - sum1*sum1/M) / M
                    block_info[block_count,1] = x
                    block_info[block_count,2] = y
                    block_count += 1 
        block_info=np.delete(block_info,slice(block_count,np.shape(image)[0]*np.shape(image)[1]),0)
        return block_info
    #==========================================================================
    def ComputeStatistics(image, block_info):
        &#34;&#34;&#34;
        Summary please.

        Args:
            image:
            block_info:

        Returns:
            sum1:
            sum2:
            subset_size:
        &#34;&#34;&#34;        
        loop_iters=len(np.arange(1,MinLevel,-0.05))
        sum1 = np.zeros((M,1,loop_iters))
        sum2 =  np.zeros((M,M,loop_iters))
        subset_size = np.zeros((loop_iters,1))
        subset_count = 0
        max_index=np.shape(block_info)[0]-1
        for p  in np.arange(1,MinLevel,-LevelStep):
            q = 0
            if p - LevelStep &gt; MinLevel:
                q = p - LevelStep

            beg_index = Clamp( round(q*max_index+LevelStep/2) + 1, 1, max_index+1 )
            end_index = Clamp( round(p*max_index+LevelStep/2) + 1, 1, max_index+1 )
            curr_sum1 = np.zeros((M, 1))
            curr_sum2 = np.zeros((M,M))
            for k in range (int(beg_index)-1,int(end_index)-1):
                curr_x = int(block_info[k,1])
                curr_y = int(block_info[k,2])
                block = np.reshape( image[curr_y-1 : curr_y+M2-1, curr_x-1 : curr_x+M1-1], (M, 1),order=&#39;F&#39; ).astype(&#34;double&#34;)
                curr_sum1 += block
                curr_sum2 +=  block * block.T
            subset_count += 1
            sum1[:,:,subset_count-1] = curr_sum1.copy()
            sum2[:,:,subset_count-1] = curr_sum2.copy()
            subset_size[subset_count-1] = end_index - beg_index
        for i in range(len(subset_size)-1,0,-1):
            sum1[:,:,i-1] += sum1[:,:,i]
            sum2[:,:,i-1] += sum2[:,:,i]
            subset_size[i-1] += subset_size[i]
        return [sum1,sum2,subset_size]
    #==========================================================================
    def ComputeUpperBound(block_info):
        &#34;&#34;&#34;
        Summary please.

        Args:
            block_info:

        Returns:
            upper_bound: 
        &#34;&#34;&#34;        
        max_index = np.shape(block_info)[0] - 1
        zero_idx=np.where(block_info[:,0]== 0)[0]
        if zero_idx.size==0:
            nozeroindex=round(UpperBoundLevel*max_index)
        else:
            nozeroindex = min(np.max(np.where(block_info[:,0]== 0)[0])+1,np.shape(block_info)[0]-1)
        index = Clamp(round(UpperBoundLevel*max_index) + 1, nozeroindex, np.shape(block_info)[0]-1)
        upper_bound = UpperBoundFactor * block_info[index,0]
        return upper_bound
    #==========================================================================
    def ApplyPCA( sum1, sum2, subset_size ):        
        &#34;&#34;&#34;
        Summary please.

        Args:
            sum1: Matrix one for PCA
            sum2: Matrix two for PCA
            subset_size: Vector for subset size

        Returns:
            eigh: Eigenvalues.
        &#34;&#34;&#34;                
        meanval = sum1 / subset_size
        cov_matrix = sum2 / subset_size - meanval * np.transpose(meanval)
        return eigh(cov_matrix)[0]
    #==========================================================================
    def GetNextEstimate( sum1, sum2, subset_size, prev_estimate, upper_bound ):
        &#34;&#34;&#34;
        Summary please.

        Args:
            sum1:
            sum2:
            subset_size:
            prev_estimate:
            upper_bound:

        Returns:
            variance: 
        &#34;&#34;&#34;                
        variance = 0;       
        for i in range(len(subset_size)):
            eigen_value = ApplyPCA( sum1[:,:,i], sum2[:,:,i], subset_size[i])
            variance=eigen_value[0]
            if variance &lt; 0.00001: #1e-5: 
                break;
            diff            = eigen_value[EigenValueCount-1] - eigen_value[0]
            diff_threshold  = EigenValueDiffThreshold * prev_estimate / subset_size[i]**0.5

            if( diff &lt; diff_threshold and variance &lt; upper_bound ):
                break;
        return variance

    #==========================================================================
   
    label = 0
    block_info = ComputeBlockInfo( image )
    if np.min(np.shape(block_info))==0:
        label = 1
        variance = np.var(image)
    else:
        idx=np.lexsort((block_info[:,2],block_info[:,0]))
        block_info = np.asarray([block_info[i,:] for i in idx])
        [sum1, sum2, subset_size] = ComputeStatistics( image, block_info )
        if subset_size[-1] == 0:
            label = 1
            variance = np.var(image)
        else:
            upper_bound = ComputeUpperBound( block_info )
            prev_variance = 0
            variance = upper_bound
            for iter in range(10):
                if( np.abs(prev_variance - variance) &lt; 0.00001): 
                    break
                prev_variance = variance
                variance = GetNextEstimate( sum1, sum2, subset_size, variance, upper_bound )
            if variance &lt; 0: 
                label = 1
                variance = np.var(image)
    variance = np.sqrt(variance)
    return [label, variance]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pyIFD" href="index.html">pyIFD</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pyIFD.NOI5.KMeans" href="#pyIFD.NOI5.KMeans">KMeans</a></code></li>
<li><code><a title="pyIFD.NOI5.PCANoise" href="#pyIFD.NOI5.PCANoise">PCANoise</a></code></li>
<li><code><a title="pyIFD.NOI5.PCANoiseLevelEstimator" href="#pyIFD.NOI5.PCANoiseLevelEstimator">PCANoiseLevelEstimator</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>